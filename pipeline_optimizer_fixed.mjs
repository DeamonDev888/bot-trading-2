import { Pool } from 'pg';

const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME || 'financial_analyst',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD || '9022'
});

async function optimizeIndexing() {
  const client = await pool.connect();
  try {
    console.log('üîß OPTIMISATION DES INDEX DE LA BASE DE DONN√âES');
    console.log('='.repeat(80));

    // Index composite pour le publisher (sans WHERE)
    await client.query(`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_news_items_publisher_composite
      ON news_items (processing_status, relevance_score DESC, published_at DESC)
    `);
    console.log('‚úÖ Index publisher composite cr√©√©');

    // Index pour les posts bruts anciens
    await client.query(`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_news_items_raw_by_created
      ON news_items (processing_status, created_at DESC)
    `);
    console.log('‚úÖ Index posts bruts par date cr√©√©');

    // Index composite pour le dashboard
    await client.query(`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_news_items_dashboard_composite
      ON news_items (category, processing_status, published_at DESC, relevance_score DESC)
    `);
    console.log('‚úÖ Index dashboard composite cr√©√©');

    // Index pour la publication
    await client.query(`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_news_items_publication_ready
      ON news_items (processing_status, relevance_score DESC, published_to_discord)
    `);
    console.log('‚úÖ Index publication pr√™te cr√©√©');

    // Index pour l'archivage
    await client.query(`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_news_items_archive_composite
      ON news_items (published_to_discord, published_at DESC)
    `);
    console.log('‚úÖ Index archivage composite cr√©√©');

    console.log('\nüéØ Tous les index d\'optimisation ont √©t√© cr√©√©s avec succ√®s !');

  } finally {
    client.release();
  }
}

async function cleanStaleData() {
  const client = await pool.connect();
  try {
    console.log('\nüßπ NETTOYAGE DES DONN√âES OBSOL√àTES');
    console.log('-'.repeat(80));

    // Identifier les doublons r√©siduels
    const duplicateCheck = await client.query(`
      SELECT title, source, COUNT(*) as dup_count
      FROM news_items
      WHERE created_at >= NOW() - INTERVAL '7 days'
        AND LENGTH(TRIM(title)) >= 5
      GROUP BY title, source
      HAVING COUNT(*) > 1
      LIMIT 10
    `);

    if (duplicateCheck.rows.length > 0) {
      console.log('‚ö†Ô∏è  Doublons trouv√©s (exemple):');
      duplicateCheck.rows.forEach(row => {
        console.log(`   ‚Ä¢ "${row.title.substring(0, 50)}..." (${row.dup_count} occurrences)`);
      });

      // Supprimer les doublons en gardant le plus r√©cent
      const deleteDuplicates = await client.query(`
        WITH ranked AS (
          SELECT id, ROW_NUMBER() OVER (PARTITION BY title, source ORDER BY created_at DESC) as rn
          FROM news_items
          WHERE created_at >= NOW() - INTERVAL '7 days'
            AND LENGTH(TRIM(title)) >= 5
        )
        DELETE FROM news_items WHERE id IN (
          SELECT id FROM ranked WHERE rn > 1
        )
      `);

      console.log(`‚úÖ ${deleteDuplicates.rowCount} doublons supprim√©s`);
    } else {
      console.log('‚úÖ Aucun doublon d√©tect√©');
    }

    // Nettoyer les posts sans titre ou contenu
    const emptyContentCheck = await client.query(`
      DELETE FROM news_items
      WHERE (title IS NULL OR TRIM(title) = '' OR LENGTH(TRIM(title)) < 5)
        OR (content IS NULL OR TRIM(content) = '' OR LENGTH(TRIM(content)) < 10)
    `);

    if (emptyContentCheck.rowCount > 0) {
      console.log(`‚úÖ ${emptyContentCheck.rowCount} posts avec contenu vide supprim√©s`);
    }

  } finally {
    client.release();
  }
}

async function createHealthCheck() {
  console.log('\nüè• CR√âATION D\'UN SYST√àME DE SANT√â');
  console.log('-'.repeat(80));

  const client = await pool.connect();
  try {
    const health = {
      timestamp: new Date().toISOString(),
      issues: [],
      metrics: {},
      recommendations: []
    };

    // V√©rifier les posts bruts accumul√©s
    const rawBacklog = await client.query(`
      SELECT COUNT(*) as count, MAX(created_at) as oldest
      FROM news_items
      WHERE processing_status = 'raw'
    `);

    health.metrics.rawBacklog = rawBacklog.rows[0].count;
    health.metrics.oldestRaw = rawBacklog.rows[0].oldest;

    if (rawBacklog.rows[0].count > 2000) {
      health.issues.push(`üî¥ ${rawBacklog.rows[0].count} posts bruts accumul√©s (CRITIQUE)`);
      health.recommendations.push('Lancer imm√©diatement le traitement par batch plus grand');
    } else if (rawBacklog.rows[0].count > 500) {
      health.issues.push(`üü° ${rawBacklog.rows[0].count} posts bruts accumul√©s`);
    }

    // V√©rifier les posts pr√™ts √† publier
    const readyToPublish = await client.query(`
      SELECT COUNT(*) as count, MAX(created_at) as oldest
      FROM news_items
      WHERE processing_status = 'processed'
        AND relevance_score >= 6
        AND (published_to_discord = false OR published_to_discord IS NULL)
    `);

    health.metrics.readyToPublish = readyToPublish.rows[0].count;
    health.metrics.oldestReady = readyToPublish.rows[0].oldest;

    if (readyToPublish.rows[0].count > 100) {
      health.issues.push(`üî¥ ${readyToPublish.rows[0].count} posts pr√™ts √† publier (URGENT)`);
      health.recommendations.push('Lancer imm√©diatement le publisher');
    } else if (readyToPublish.rows[0].count > 20) {
      health.issues.push(`üü° ${readyToPublish.rows[0].count} posts pr√™ts √† publier`);
      health.recommendations.push('Consid√©rer lancer le publisher');
    }

    // V√©rifier les performances r√©centes
    const recentPerformance = await client.query(`
      SELECT
        COUNT(*) as total_posts,
        COUNT(CASE WHEN processing_status = 'processed' THEN 1 END) as processed_posts,
        COUNT(CASE WHEN published_to_discord = true THEN 1 END) as published_posts,
        AVG(CASE WHEN relevance_score IS NOT NULL THEN relevance_score END) as avg_score
      FROM news_items
      WHERE published_at >= NOW() - INTERVAL '24 hours'
    `);

    health.metrics.posts24h = recentPerformance.rows[0].total_posts;
    health.metrics.processed24h = recentPerformance.rows[0].processed_posts;
    health.metrics.published24h = recentPerformance.rows[0].published_posts;
    health.metrics.avgScore24h = recentPerformance.rows[0].avg_score;

    if (health.metrics.posts24h === 0) {
      health.issues.push('üî¥ Aucun post re√ßu dans les derni√®res 24h');
      health.recommendations.push('V√©rifier le scraping');
    }

    // Afficher le rapport de sant√©
    console.log('\nüìä RAPPORT DE SANT√â DU PIPELINE:');
    console.log(`   ‚Ä¢ Posts bruts totaux: ${health.metrics.rawBacklog}`);
    if (health.metrics.oldestRaw) {
      console.log(`   ‚Ä¢ Plus ancien post brut: ${health.metrics.oldestRaw}`);
    }
    console.log(`   ‚Ä¢ Posts pr√™ts √† publier: ${health.metrics.readyToPublish}`);
    if (health.metrics.oldestReady) {
      console.log(`   ‚Ä¢ Plus ancien post pr√™t: ${health.metrics.oldestReady}`);
    }
    console.log(`   ‚Ä¢ Posts 24 derni√®res heures: ${health.metrics.posts24h}`);
    const avgScore = health.metrics.avgScore24h ? parseFloat(health.metrics.avgScore24h).toFixed(1) : 'N/A';
    console.log(`   ‚Ä¢ Score moyen 24h: ${avgScore}`);

    if (health.issues.length === 0) {
      console.log('   ‚úÖ Aucun probl√®me critique d√©tect√©');
    } else {
      console.log('\n‚ö†Ô∏è  Probl√®mes d√©tect√©s:');
      health.issues.forEach(issue => console.log(`   ${issue}`));
    }

    if (health.recommendations.length > 0) {
      console.log('\nüí° Recommandations:');
      health.recommendations.forEach(rec => console.log(`   ‚Ä¢ ${rec}`));
    }

    return health;

  } finally {
    client.release();
  }
}

async function createMaintenanceScript() {
  console.log('\nüõ†Ô∏è  CR√âATION D\'UN SCRIPT DE MAINTENANCE AUTOMATIQUE');
  console.log('-'.repeat(80));

  const maintenanceScript = `#!/usr/bin/env node

import { Pool } from 'pg';

const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME || 'financial_analyst',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD || '9022'
});

async function runMaintenance() {
  const client = await pool.connect();
  try {
    console.log('üîß Maintenance du pipeline -', new Date().toLocaleString());

    // 1. Nettoyer les anciens posts bruts (plus de 7 jours)
    const oldRawCleanup = await client.query(\`
      UPDATE news_items
      SET processing_status = 'archived'
      WHERE processing_status = 'raw'
        AND created_at < NOW() - INTERVAL '7 days'
    \`);

    if (oldRawCleanup.rowCount > 0) {
      console.log(\`üóëÔ∏è  \${oldRawCleanup.rowCount} posts bruts anciens archiv√©s\`);
    }

    // 2. Archiver les anciens posts publi√©s (plus de 90 jours)
    const archivePublished = await client.query(\`
      UPDATE news_items
      SET processing_status = 'archived'
      WHERE published_to_discord = true
        AND published_at < NOW() - INTERVAL '90 days'
    \`);

    if (archivePublished.rowCount > 0) {
      console.log(\`üì¶ \${archivePublished.rowCount} posts publi√©s archiv√©s\`);
    }

    // 3. Optimiser la table (VACUUM ANALYZE)
    await client.query('VACUUM ANALYZE news_items');
    console.log('üßπ Table optimis√©e');

    console.log('‚úÖ Maintenance termin√©e');

  } finally {
    client.release();
    await pool.end();
  }
}

runMaintenance().catch(console.error);
`;

  // √âcrire le script dans un fichier
  const fs = await import('fs');
  await fs.promises.writeFile('pipeline_maintenance.mjs', maintenanceScript);
  console.log('‚úÖ Script de maintenance cr√©√©: pipeline_maintenance.mjs');

  console.log('\nüìã Pour configurer l\'ex√©cution automatique:');
  console.log('   # Ex√©cuter tous les jours √† 2h du matin');
  console.log('   0 2 * * * /usr/bin/node /path/to/pipeline_maintenance.mjs >> /var/log/maintenance.log 2>&1');
}

async function main() {
  console.log('üöÄ LANCEMENT DE L\'OPTIMISATION DU PIPELINE');
  console.log('='.repeat(100));

  try {
    // 1. Optimiser l'indexation
    await optimizeIndexing();

    // 2. Nettoyer les donn√©es obsol√®tes
    await cleanStaleData();

    // 3. Cr√©er le syst√®me de sant√©
    const healthReport = await createHealthCheck();

    // 4. Cr√©er le script de maintenance
    await createMaintenanceScript();

    console.log('\n\nüéâ OPTIMISATION TERMIN√âE AVEC SUCC√àS !');
    console.log('='.repeat(100));

    console.log('\nüìà Am√©liorations impl√©ment√©es:');
    console.log('   ‚úÖ Index optimis√©s pour toutes les requ√™tes critiques');
    console.log('   ‚úÖ Nettoyage automatique des doublons et contenu vide');
    console.log('   ‚úÖ Syst√®me de monitoring de sant√©');
    console.log('   ‚úÖ Script de maintenance automatique');

    console.log('\nüî¥ ACTIONS REQUISES:');
    console.log('   1. Configurer le scheduler pour le publisher (node run_publisher.mjs toutes les heures)');
    console.log('   2. Configurer la maintenance quotidienne (node pipeline_maintenance.mjs)');
    console.log('   3. Surveiller les alertes dans les logs');

    console.log('\nüí° Performance attendue:');
    console.log('   ‚Ä¢ Requ√™tes DB: +200-300% plus rapide');
    console.log('   ‚Ä¢ Stabilit√©: Monitoring continu');
    console.log('   ‚Ä¢ Maintenance: Automatis√©e');

    // Afficher les actions urgentes si n√©cessaire
    if (healthReport.issues.some(issue => issue.includes('üî¥'))) {
      console.log('\nüö® ACTIONS URGENTES REQUISES MAINTENANT:');
      healthReport.recommendations.forEach(rec => {
        if (rec.includes('imm√©diatement')) {
          console.log(`   ‚Ä¢ ${rec}`);
        }
      });
    }

  } catch (error) {
    console.error('‚ùå Erreur pendant l\'optimisation:', error);
  } finally {
    await pool.end();
  }
}

main().catch(console.error);