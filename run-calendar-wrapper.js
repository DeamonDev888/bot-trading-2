#!/usr/bin/env node

/**
 * Wrapper robuste pour l'exÃ©cution du pipeline calendrier via cron
 * GÃ¨re les erreurs, timeout, et logging dÃ©taillÃ©
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration
const CONFIG = {
  timeout: 300000, // 5 minutes
  logFile: path.join(process.cwd(), 'calendar-pipeline.log'),
  maxLogSize: 10 * 1024 * 1024, // 10MB
  retries: 3,
  retryDelay: 5000
};

// Logger avec rotation
function logToFile(message) {
  const timestamp = new Date().toISOString();
  const logEntry = `[${timestamp}] ${message}\n`;

  try {
    fs.appendFileSync(CONFIG.logFile, logEntry);
    console.log(message);

    // VÃ©rifier la taille du fichier et faire rotation si nÃ©cessaire
    const stats = fs.statSync(CONFIG.logFile);
    if (stats.size > CONFIG.maxLogSize) {
      const backupFile = CONFIG.logFile + '.old';
      fs.renameSync(CONFIG.logFile, backupFile);
    }
  } catch (error) {
    console.error('Erreur logging:', error.message);
  }
}

// Fonction principale avec retry
async function runCalendarPipelineWithRetry(retryCount = 0) {
  logToFile(`ğŸ”„ DÃ‰MARRAGE PIPELINE (tentative ${retryCount + 1}/${CONFIG.retries})`);

  try {
    // Importer les modules dynamiquement
    const { TradingEconomicsScraper } = await import('./dist/backend/ingestion/TradingEconomicsScraper.js');
    const { RougePulseAgent } = await import('./dist/backend/agents/RougePulseAgent.js');
    const { CalendarPublisher } = await import('./dist/backend/agents/CalendarPublisher.js');

    // CrÃ©er les instances
    const scraper = new TradingEconomicsScraper();
    const rougePulse = new RougePulseAgent();
    const publisher = new CalendarPublisher();

    logToFile('âœ… Instances crÃ©Ã©es, dÃ©marrage du pipeline...');

    // Ã‰tape 1: Scraping
    logToFile('ğŸ“… [1/3] Scraping Trading Economics...');
    const events = await scraper.scrapeUSCalendar();
    logToFile(`ğŸ“Š ${events.length} Ã©vÃ©nements rÃ©cupÃ©rÃ©s`);

    if (events.length > 0) {
      await scraper.saveEvents(events);
      logToFile('ğŸ’¾ Ã‰vÃ©nements sauvegardÃ©s en base');
    } else {
      logToFile('âš ï¸ Aucun Ã©vÃ©nement trouvÃ©');
    }

    // Pause entre Ã©tapes
    await new Promise(resolve => setTimeout(resolve, 2000));

    // Ã‰tape 2: Filtrage
    logToFile('ğŸ” [2/3] Filtrage RougePulse...');
    const filtered = await rougePulse.filterCalendarEvents();
    logToFile(`ğŸ“Š ${filtered.critical_events.length} critiques, ${filtered.high_impact_events.length} forts`);

    // Pause entre Ã©tapes
    await new Promise(resolve => setTimeout(resolve, 2000));

    // Ã‰tape 3: Publication avec les donnÃ©es filtrÃ©es
    logToFile('ğŸ“¢ [3/3] Publication avec donnÃ©es filtrÃ©es...');

    // Passer les Ã©vÃ©nements filtrÃ©s au publisher
    let result;
    if (filtered.critical_events.length > 0 || filtered.high_impact_events.length > 0) {
      // Utiliser les donnÃ©es filtrÃ©es par RougePulse
      result = await publisher.publishFilteredCalendar(filtered);
      logToFile(`âœ… Publication avec donnÃ©es filtrÃ©es: ${filtered.critical_events.length + filtered.high_impact_events.length} Ã©vÃ©nements`);
    } else {
      // Publication standard avec tous les Ã©vÃ©nements de la base
      result = await publisher.publishDailyCalendar();
      logToFile(`ğŸ“… Publication standard: ${result.published_events || 0} Ã©vÃ©nements`);
    }

    if (result.success) {
      logToFile(`âœ… Publication rÃ©ussie: ${result.published_events || 0} messages`);
    } else {
      logToFile(`âŒ Publication Ã©chouÃ©e: ${result.error}`);
    }

    // VÃ©rification alertes critiques
    try {
      const alertResult = await publisher.publishCriticalAlerts();
      logToFile(`ğŸš¨ Alertes critiques: ${alertResult.published_events || 0}`);
    } catch (error) {
      logToFile(`âš ï¸ Erreur alertes critiques: ${error.message}`);
    }

    // Nettoyage
    logToFile('ğŸ§¹ Nettoyage des connexions...');
    await scraper.close();
    await rougePulse.close();
    await publisher.close();

    logToFile('ğŸ‰ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS');
    return true;

  } catch (error) {
    logToFile(`âŒ ERREUR PIPELINE: ${error.message}`);
    logToFile(`Stack: ${error.stack}`);

    // Retry logic
    if (retryCount < CONFIG.retries - 1) {
      logToFile(`ğŸ”„ Nouvelle tentative dans ${CONFIG.retryDelay/1000}s...`);
      await new Promise(resolve => setTimeout(resolve, CONFIG.retryDelay));
      return runCalendarPipelineWithRetry(retryCount + 1);
    } else {
      logToFile(`ğŸ’¥ Ã‰CHEC APRÃˆS ${CONFIG.retries} tentatives`);
      return false;
    }
  }
}

// Gestion du timeout
async function runWithTimeout() {
  return new Promise(async (resolve, reject) => {
    const timeout = setTimeout(() => {
      reject(new Error('Timeout du pipeline (5 minutes)'));
    }, CONFIG.timeout);

    try {
      const result = await runCalendarPipelineWithRetry();
      clearTimeout(timeout);
      resolve(result);
    } catch (error) {
      clearTimeout(timeout);
      reject(error);
    }
  });
}

// DÃ©marrage principal
async function main() {
  logToFile('='.repeat(50));
  logToFile('ğŸš€ LANCEMENT DU PIPELINE CALENDRIER AUTOMATISÃ‰');
  logToFile(`â° Heure: ${new Date().toLocaleString('fr-FR')}`);
  logToFile('='.repeat(50));

  try {
    const success = await runWithTimeout();

    if (success) {
      logToFile('âœ… Pipeline terminÃ© avec succÃ¨s');
      process.exit(0);
    } else {
      logToFile('âŒ Pipeline terminÃ© avec des erreurs');
      process.exit(1);
    }
  } catch (error) {
    logToFile(`ğŸ’¥ ERREUR FATALE: ${error.message}`);
    process.exit(1);
  }
}

// Gestion des signaux pour arrÃªt propre
process.on('SIGTERM', () => {
  logToFile('ğŸ›‘ Signal SIGTERM reÃ§u, arrÃªt...');
  process.exit(0);
});

process.on('SIGINT', () => {
  logToFile('ğŸ›‘ Signal SIGINT reÃ§u, arrÃªt...');
  process.exit(0);
});

// DÃ©marrage
main();