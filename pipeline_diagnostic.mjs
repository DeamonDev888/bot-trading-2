import { Pool } from 'pg';

const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME || 'financial_analyst',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD || '9022'
});

async function runDiagnostic() {
  const client = await pool.connect();
  try {
    console.log('='.repeat(80));
    console.log('DIAGNOSTIC COMPLET DU PIPELINE DE NEWS X/TWITTER');
    console.log('='.repeat(80));

    // 1. Statistiques globales par cat√©gorie
    console.log('\nüìä STATISTIQUES GLOBALES PAR CAT√âGORIE');
    console.log('-'.repeat(50));

    const globalStats = await client.query(`
      SELECT
        category,
        COUNT(*) as total_posts,
        COUNT(CASE WHEN processing_status = 'raw' THEN 1 END) as raw_posts,
        COUNT(CASE WHEN processing_status = 'processed' THEN 1 END) as processed_posts,
        COUNT(CASE WHEN relevance_score >= 6 THEN 1 END) as high_score_posts,
        COUNT(CASE WHEN published_to_discord = true THEN 1 END) as published_posts,
        COUNT(CASE WHEN published_at >= NOW() - INTERVAL '24 hours' THEN 1 END) as last_24h,
        COUNT(CASE WHEN published_at >= NOW() - INTERVAL '7 days' THEN 1 END) as last_7d
      FROM news_items
      WHERE category IN ('FINANCE', 'IA')
      GROUP BY category
    `);

    globalStats.rows.forEach(stat => {
      console.log(`\nüìÅ Cat√©gorie: ${stat.category}`);
      console.log(`   Total posts:          ${stat.total_posts}`);
      console.log(`   Posts bruts (raw):    ${stat.raw_posts} (${((stat.raw_posts/stat.total_posts)*100).toFixed(1)}%)`);
      console.log(`   Posts trait√©s:         ${stat.processed_posts} (${((stat.processed_posts/stat.total_posts)*100).toFixed(1)}%)`);
      console.log(`   Posts score ‚â• 6:       ${stat.high_score_posts} (${((stat.high_score_posts/stat.total_posts)*100).toFixed(1)}%)`);
      console.log(`   Posts publi√©s:         ${stat.published_posts} (${((stat.published_posts/stat.total_posts)*100).toFixed(1)}%)`);
      console.log(`   Posts 24 derni√®res heures: ${stat.last_24h}`);
      console.log(`   Posts 7 derniers jours:   ${stat.last_7d}`);
    });

    // 2. Analyse des posts en attente de traitement
    console.log('\n\nüîÑ POSTS EN ATTENTE DE TRAITEMENT (RAW)');
    console.log('-'.repeat(50));

    const rawPosts = await client.query(`
      SELECT category, COUNT(*) as count
      FROM news_items
      WHERE processing_status = 'raw'
        AND category IN ('FINANCE', 'IA')
        AND created_at >= NOW() - INTERVAL '48 hours'
      GROUP BY category
    `);

    console.log('Posts bruts des 48 derni√®res heures:');
    rawPosts.rows.forEach(row => {
      console.log(`   ${row.category}: ${row.count} posts en attente`);
    });

    // 3. Posts pr√™ts √† publier mais non publi√©s
    console.log('\n\nüö® POSTS PR√äTS √Ä PUBLIER (MAIS NON PUBLI√âS)');
    console.log('-'.repeat(50));

    const readyToPublish = await client.query(`
      SELECT
        category,
        COUNT(*) as ready_count,
        AVG(relevance_score) as avg_score
      FROM news_items
      WHERE processing_status = 'processed'
        AND relevance_score >= 6
        AND (published_to_discord = false OR published_to_discord IS NULL)
        AND category IN ('FINANCE', 'IA')
        AND published_at >= NOW() - INTERVAL '7 days'
      GROUP BY category
    `);

    if (readyToPublish.rows.length > 0) {
      readyToPublish.rows.forEach(row => {
        const avgScore = row.avg_score ? parseFloat(row.avg_score).toFixed(1) : 'N/A';
        console.log(`   ${row.category}: ${row.ready_count} posts pr√™ts (score moyen: ${avgScore})`);
      });
    } else {
      console.log('   ‚úÖ Aucun post en attente de publication');
    }

    // 4. Analyse par compte/source
    console.log('\n\nüë• TOP 15 DES COMPTES PAR ACTIVIT√â R√âCENTE');
    console.log('-'.repeat(50));

    const topAccounts = await client.query(`
      SELECT
        source,
        category,
        COUNT(*) as total_posts,
        COUNT(CASE WHEN processing_status = 'raw' THEN 1 END) as raw_count,
        COUNT(CASE WHEN relevance_score >= 6 THEN 1 END) as high_score_count,
        COUNT(CASE WHEN published_to_discord = true THEN 1 END) as published_count,
        MAX(published_at) as latest_post
      FROM news_items
      WHERE category IN ('FINANCE', 'IA')
        AND published_at >= NOW() - INTERVAL '7 days'
      GROUP BY source, category
      ORDER BY total_posts DESC
      LIMIT 15
    `);

    topAccounts.rows.forEach((row, i) => {
      console.log(`${(i + 1).toString().padStart(2)}. ${row.source.padEnd(25)} [${row.category.padEnd(7)}]`);
      console.log(`    Total: ${row.total_posts} | Bruts: ${row.raw_count} | Score‚â•6: ${row.high_score_count} | Publi√©s: ${row.published_count}`);
      console.log(`    Dernier post: ${row.latest_post}`);
      console.log('');
    });

    // 5. Derniers posts publi√©s sur Discord
    console.log('\n\nüì¢ DERNIERS POSTS PUBLI√âS SUR DISCORD');
    console.log('-'.repeat(50));

    const latestPublished = await client.query(`
      SELECT source, title, category, relevance_score, published_at
      FROM news_items
      WHERE published_to_discord = true
        AND category IN ('FINANCE', 'IA')
      ORDER BY published_at DESC
      LIMIT 10
    `);

    if (latestPublished.rows.length > 0) {
      latestPublished.rows.forEach((row, i) => {
        console.log(`${(i + 1).toString().padStart(2)}. [${row.relevance_score}/10] ${row.source.padEnd(20)} [${row.category}]`);
        console.log(`    ${row.title.substring(0, 80)}...`);
        console.log(`    Publi√© le: ${row.published_at}`);
        console.log('');
      });
    } else {
      console.log('   ‚ùå Aucun post publi√© r√©cemment');
    }

    // 6. Analyse des probl√®mes de scraping
    console.log('\n\n‚ö†Ô∏è  ANALYSE DES PROBL√àMES');
    console.log('-'.repeat(50));

    console.log('Dernier rapport de scraping:');
    console.log(`   ‚Ä¢ Total feeds: 310`);
    console.log(`   ‚Ä¢ Feeds r√©ussis: 127 (41%)`);
    console.log(`   ‚Ä¢ Feeds √©chou√©s: 183 (59%)`);
    console.log(`   ‚Ä¢ Total items trouv√©s: 131`);
    console.log(`   ‚Ä¢ Soit seulement ~0.4 items par feed en moyenne`);

    console.log('\nCauses probables des posts manqu√©s:');
    console.log('   1. Taux d\'√©chec √©lev√© du scraping (59% des feeds √©chouent)');
    console.log('   2. "No items found" pour la plupart des comptes');
    console.log('   3. Le scraper trouve peu de contenu par feed');
    console.log('   4. Possible probl√®me avec l\'API ou parsing');

    console.log('\nüí° RECOMMANDATIONS');
    console.log('-'.repeat(50));
    console.log('1. V√©rifier le scraping: beaucoup de feeds retournent "No items found"');
    console.log('2. Ajouter des logs d√©taill√©s pour suivre les posts par compte');
    console.log('3. V√©rifier si les comptes X/Twitter ont des restrictions');
    console.log('4. Tester manuellement quelques feeds probl√©matiques');

  } finally {
    client.release();
    await pool.end();
  }
}

runDiagnostic().catch(console.error);